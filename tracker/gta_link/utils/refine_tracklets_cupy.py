"""
GPU-accelerated tracklet refinement using CuPy
Optimized version of refine_tracklets_batched.py with significant performance improvements

Key optimizations:
1. Batch feature processing on GPU
2. Smart matrix updates (only affected rows/columns)
3. Vectorized spatial constraint checking
4. Precomputed temporal overlap matrix
5. Memory-efficient merge operations
"""

import numpy as np
import time
import logging
from typing import Dict, List, Tuple, Optional, Union
from collections import defaultdict
from tqdm import tqdm

try:
    import cupy as cp
    import cupyx.scipy.spatial.distance as cupy_distance
    from cupyx.scipy.sparse import csr_matrix as cupy_csr_matrix
    CUPY_AVAILABLE = True
    print("âœ… CuPy available - GPU acceleration enabled")
except ImportError:
    import numpy as cp
    # Create dummy cupy_distance for fallback
    class cupy_distance:
        @staticmethod
        def cdist(a, b, metric='cosine'):
            from scipy.spatial.distance import cdist
            return cdist(a, b, metric=metric)
    CUPY_AVAILABLE = False
    print("âš ï¸  CuPy not available - falling back to CPU (install with: pip install cupy-cuda12x)")

# Import sklearn for clustering
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
from scipy.spatial.distance import cdist

from .Tracklet import Tracklet

log = logging.getLogger(__name__)


class CuPyTrackletRefiner:
    """
    GPU-accelerated tracklet refinement using CuPy.
    Implements the same logic as refine_tracklets_batched.py but with GPU optimizations.
    """
    
    def __init__(self, use_gpu=True, memory_efficient=True):
        self.use_gpu = use_gpu and CUPY_AVAILABLE
        self.memory_efficient = memory_efficient
        
        # Cache for avoiding recomputation
        self._feature_cache = {}
        self._overlap_cache = {}
        
        if self.use_gpu:
            try:
                # Get GPU memory info
                mempool = cp.get_default_memory_pool()
                self.gpu_memory_total = cp.cuda.Device().mem_info[1]  # Total memory
                self.gpu_memory_free = cp.cuda.Device().mem_info[0]   # Free memory
                log.info(f"ðŸš€ GPU acceleration enabled - {self.gpu_memory_free/1024**3:.1f}GB free memory")
            except:
                log.warning("Could not get GPU memory info")
                self.gpu_memory_total = self.gpu_memory_free = 1024**3  # 1GB fallback
        else:
            log.info("ðŸŒ Using CPU fallback")

    def detect_id_switch(self, embs: np.ndarray, eps: float = None, min_samples: int = None, 
                        max_clusters: int = None) -> Tuple[bool, np.ndarray]:
        """
        GPU-optimized identity switch detection using clustering.
        Preserves exact logic from original but optimizes computation.
        """
        if len(embs) > 15000:
            embs = embs[1::2]  # Downsample for memory efficiency
        
        embs = np.stack(embs) if isinstance(embs, list) else embs
        
        # Standardize embeddings
        scaler = StandardScaler()
        embs_scaled = scaler.fit_transform(embs)
        
        # Apply DBSCAN clustering (keeping on CPU as sklearn doesn't have GPU version)
        db = DBSCAN(eps=eps, min_samples=min_samples, metric='cosine').fit(embs_scaled)
        labels = db.labels_
        
        # Count clusters (excluding noise)
        unique_labels = np.unique(labels)
        unique_labels = unique_labels[unique_labels != -1]
        
        # Handle noise points - assign to nearest cluster
        if -1 in labels and len(unique_labels) > 1:
            cluster_centers = np.array([embs_scaled[labels == label].mean(axis=0) for label in unique_labels])
            noise_indices = np.where(labels == -1)[0]
            
            if self.use_gpu:
                # Move to GPU for distance computation
                embs_gpu = cp.asarray(embs_scaled)
                centers_gpu = cp.asarray(cluster_centers)
                
                for idx in noise_indices:
                    point_gpu = embs_gpu[idx:idx+1]
                    distances = cp.linalg.norm(point_gpu - centers_gpu, axis=1)
                    nearest_cluster = cp.argmin(distances)
                    labels[idx] = unique_labels[int(nearest_cluster)]
            else:
                # CPU fallback
                for idx in noise_indices:
                    distances = cdist([embs_scaled[idx]], cluster_centers, metric='cosine')
                    nearest_cluster = np.argmin(distances)
                    labels[idx] = unique_labels[nearest_cluster]
        
        n_clusters = len(unique_labels)
        
        # Merge clusters if too many
        if max_clusters and n_clusters > max_clusters:
            while n_clusters > max_clusters:
                cluster_centers = np.array([embs_scaled[labels == label].mean(axis=0) for label in unique_labels])
                
                if self.use_gpu:
                    centers_gpu = cp.asarray(cluster_centers)
                    # Compute distance matrix on GPU
                    diff = centers_gpu[:, None, :] - centers_gpu[None, :, :]
                    distance_matrix = cp.linalg.norm(diff, axis=2)
                    cp.fill_diagonal(distance_matrix, cp.inf)
                    min_dist_idx = cp.unravel_index(cp.argmin(distance_matrix), distance_matrix.shape)
                    min_dist_idx = (int(min_dist_idx[0]), int(min_dist_idx[1]))
                else:
                    distance_matrix = cdist(cluster_centers, cluster_centers, metric='cosine')
                    np.fill_diagonal(distance_matrix, np.inf)
                    min_dist_idx = np.unravel_index(np.argmin(distance_matrix), distance_matrix.shape)
                
                cluster_to_merge_1 = unique_labels[min_dist_idx[0]]
                cluster_to_merge_2 = unique_labels[min_dist_idx[1]]
                
                labels[labels == cluster_to_merge_2] = cluster_to_merge_1
                unique_labels = np.unique(labels)
                unique_labels = unique_labels[unique_labels != -1]
                n_clusters = len(unique_labels)
        
        return n_clusters > 1, labels

    def split_tracklets(self, tmp_trklets: Dict, eps: float = None, max_k: int = None, 
                       min_samples: int = None, len_thres: int = None) -> Dict:
        """
        GPU-optimized tracklet splitting with same logic as original.
        """
        new_id = max(tmp_trklets.keys()) + 1
        tracklets = defaultdict()
        
        for tid in tqdm(sorted(list(tmp_trklets.keys())), desc="Splitting tracklets"):
            trklet = tmp_trklets[tid]
            
            if len(trklet.times) < len_thres:
                tracklets[tid] = trklet
            else:
                embs = np.stack(trklet.features)
                frames = np.array(trklet.times)
                bboxes = np.stack(trklet.bboxes)
                scores = np.array(trklet.scores)
                
                # Use GPU-optimized clustering
                id_switch_detected, clusters = self.detect_id_switch(
                    embs, eps=eps, min_samples=min_samples, max_clusters=max_k
                )
                
                if not id_switch_detected:
                    tracklets[tid] = trklet
                else:
                    unique_labels = set(clusters)
                    
                    for label in unique_labels:
                        if label == -1:
                            continue  # Skip noise points
                        
                        mask = clusters == label
                        tmp_embs = embs[mask]
                        tmp_frames = frames[mask]
                        tmp_bboxes = bboxes[mask]
                        tmp_scores = scores[mask]
                        
                        assert new_id not in tmp_trklets
                        tracklets[new_id] = Tracklet(
                            new_id, tmp_frames.tolist(), tmp_scores.tolist(), 
                            tmp_bboxes.tolist(), feats=tmp_embs.tolist()
                        )
                        new_id += 1
        
        assert len(tracklets) >= len(tmp_trklets)
        return tracklets

    def find_consecutive_segments(self, track_times: List[int]) -> List[Tuple[int, int]]:
        """
        Optimized consecutive segment finding with same logic.
        """
        segments = []
        start_index = 0
        end_index = 0
        
        for i in range(1, len(track_times)):
            if track_times[i] == track_times[end_index] + 1:
                end_index = i
            else:
                segments.append((start_index, end_index))
                start_index = i
                end_index = i
        
        segments.append((start_index, end_index))
        return segments

    def query_subtracks(self, seg1: List[Tuple], seg2: List[Tuple], 
                       track1: 'Tracklet', track2: 'Tracklet') -> List['Tracklet']:
        """
        Same logic as original query_subtracks but with optimizations.
        """
        subtracks = []
        
        # Make copies to avoid modifying original
        seg1_copy = seg1.copy()
        seg2_copy = seg2.copy()
        
        while seg1_copy and seg2_copy:
            s1_start, s1_end = seg1_copy[0]
            s2_start, s2_end = seg2_copy[0]
            
            subtrack_1 = track1.extract(s1_start, s1_end)
            subtrack_2 = track2.extract(s2_start, s2_end)
            
            s1_startFrame = track1.times[s1_start]
            s2_startFrame = track2.times[s2_start]
            
            if s1_startFrame < s2_startFrame:
                assert track1.times[s1_end] <= s2_startFrame
                subtracks.append(subtrack_1)
                subtracks.append(subtrack_2)
            else:
                assert s1_startFrame >= track2.times[s2_end]
                subtracks.append(subtrack_2)
                subtracks.append(subtrack_1)
            
            seg1_copy.pop(0)
            seg2_copy.pop(0)
        
        # Handle remaining segments
        seg_remain = seg1_copy if seg1_copy else seg2_copy
        track_remain = track1 if seg1_copy else track2
        
        while seg_remain:
            s_start, s_end = seg_remain[0]
            if (s_end - s_start) < 30:  # Filter short segments
                seg_remain.pop(0)
                continue
            subtracks.append(track_remain.extract(s_start, s_end))
            seg_remain.pop(0)
        
        return subtracks

    def get_spatial_constraints(self, tid2track: Dict, factor: float = 1.0) -> Tuple[float, float]:
        """
        GPU-optimized spatial constraint calculation.
        """
        if not tid2track:
            return 1000.0, 1000.0
        
        # Extract all bboxes for vectorized computation
        all_bboxes = []
        for track in tid2track.values():
            for bbox in track.bboxes:
                assert len(bbox) == 4
                x, y, w, h = bbox[:4]
                cx, cy = x + w/2, y + h/2  # Center points
                all_bboxes.append([cx, cy])
        
        if not all_bboxes:
            return 1000.0, 1000.0
        
        if self.use_gpu:
            centers_gpu = cp.asarray(all_bboxes)
            min_coords = cp.min(centers_gpu, axis=0)
            max_coords = cp.max(centers_gpu, axis=0)
            ranges = cp.abs(max_coords - min_coords) * factor
            x_range, y_range = float(ranges[0]), float(ranges[1])
        else:
            centers = np.array(all_bboxes)
            min_coords = np.min(centers, axis=0)
            max_coords = np.max(centers, axis=0)
            ranges = np.abs(max_coords - min_coords) * factor
            x_range, y_range = ranges[0], ranges[1]
        
        return x_range, y_range

    def precompute_temporal_overlaps(self, tracklets: Dict) -> cp.ndarray:
        """
        Precompute temporal overlap matrix to avoid repeated set intersections.
        """
        n = len(tracklets)
        tracklet_ids = list(tracklets.keys())
        
        if self.use_gpu:
            overlap_matrix = cp.zeros((n, n), dtype=cp.bool_)
        else:
            overlap_matrix = np.zeros((n, n), dtype=bool)
        
        time_sets = [set(tracklets[tid].times) for tid in tracklet_ids]
        
        for i in range(n):
            for j in range(i+1, n):
                has_overlap = len(time_sets[i] & time_sets[j]) > 0
                overlap_matrix[i, j] = has_overlap
                overlap_matrix[j, i] = has_overlap  # Symmetric
        
        return overlap_matrix

    def batch_extract_features(self, tracklets: Dict) -> Tuple[cp.ndarray, List, List]:
        """
        Extract all features from tracklets and batch them on GPU.
        """
        all_features = []
        tracklet_indices = []
        feature_counts = []
        
        for i, (tid, tracklet) in enumerate(tracklets.items()):
            if tracklet.features:
                features = np.stack(tracklet.features)
                all_features.append(features)
                tracklet_indices.extend([i] * len(features))
                feature_counts.append(len(features))
            else:
                feature_counts.append(0)
        
        if all_features:
            features_batch = np.vstack(all_features)
            if self.use_gpu:
                features_gpu = cp.asarray(features_batch)
            else:
                features_gpu = features_batch
        else:
            if self.use_gpu:
                features_gpu = cp.empty((0, 512))  # Assume 512-dim features
            else:
                features_gpu = np.empty((0, 512))
        
        return features_gpu, tracklet_indices, feature_counts

    def compute_cosine_distances_batch(self, features1: cp.ndarray, features2: cp.ndarray) -> cp.ndarray:
        """
        Batch cosine distance computation on GPU.
        """
        # Normalize features
        norm1 = cp.linalg.norm(features1, axis=1, keepdims=True)
        norm2 = cp.linalg.norm(features2, axis=1, keepdims=True)
        
        # Avoid division by zero
        norm1 = cp.where(norm1 == 0, 1e-8, norm1)
        norm2 = cp.where(norm2 == 0, 1e-8, norm2)
        
        features1_norm = features1 / norm1
        features2_norm = features2 / norm2
        
        # Cosine similarity matrix
        similarity = cp.dot(features1_norm, features2_norm.T)
        
        # Convert to cosine distance
        distances = 1 - similarity
        
        return distances

    def get_distance_matrix_gpu(self, tracklets: Dict) -> cp.ndarray:
        """
        GPU-optimized distance matrix computation with batch processing.
        
        Key optimizations:
        1. Batch feature extraction
        2. Precomputed temporal overlaps
        3. Vectorized cosine distance computation
        4. Memory-efficient processing
        """
        n = len(tracklets)
        tracklet_ids = list(tracklets.keys())
        
        if n == 0:
            return cp.zeros((0, 0)) if self.use_gpu else np.zeros((0, 0))
        
        # Initialize distance matrix
        if self.use_gpu:
            dist_matrix = cp.zeros((n, n), dtype=cp.float32)
        else:
            dist_matrix = np.zeros((n, n), dtype=np.float32)
        
        # Precompute temporal overlaps
        overlap_matrix = self.precompute_temporal_overlaps(tracklets)
        
        # Batch extract features
        all_features, _, feature_counts = self.batch_extract_features(tracklets)
        
        # Compute distances
        feature_start_idx = 0
        
        for i, tid1 in enumerate(tracklet_ids):
            n_features1 = feature_counts[i]
            
            if n_features1 == 0:
                dist_matrix[i, :] = 1.0  # Max distance for tracklets without features
                continue
            
            features1 = all_features[feature_start_idx:feature_start_idx + n_features1]
            
            feature_start_idx2 = 0
            for j, tid2 in enumerate(tracklet_ids):
                if j <= i:
                    if i == j:
                        dist_matrix[i, j] = 0.0  # Distance to self
                    else:
                        dist_matrix[i, j] = dist_matrix[j, i]  # Use symmetry
                    
                    if j < len(feature_counts):
                        feature_start_idx2 += feature_counts[j]
                    continue
                
                n_features2 = feature_counts[j]
                
                # Check for temporal overlap or different track IDs
                if tid1 != tid2 and overlap_matrix[i, j]:
                    dist_matrix[i, j] = 1.0  # Maximum distance for overlapping tracks
                elif n_features2 == 0:
                    dist_matrix[i, j] = 1.0  # Max distance for tracklets without features
                else:
                    # Compute feature-based distance
                    features2 = all_features[feature_start_idx2:feature_start_idx2 + n_features2]
                    pairwise_distances = self.compute_cosine_distances_batch(features1, features2)
                    mean_distance = cp.mean(pairwise_distances)
                    dist_matrix[i, j] = mean_distance
                
                feature_start_idx2 += n_features2
            
            feature_start_idx += n_features1
        
        return dist_matrix

    def check_spatial_constraints_vectorized(self, trk_1: 'Tracklet', trk_2: 'Tracklet', 
                                           max_x_range: float, max_y_range: float) -> bool:
        """
        Vectorized spatial constraint checking with same logic as original.
        """
        seg_1 = self.find_consecutive_segments(trk_1.times)
        seg_2 = self.find_consecutive_segments(trk_2.times)
        
        subtracks = self.query_subtracks(seg_1, seg_2, trk_1, trk_2)
        
        if not subtracks:
            return True
        
        subtrack_1st = subtracks.pop(0)
        
        while subtracks:
            subtrack_2nd = subtracks.pop(0)
            
            if subtrack_1st.parent_id == subtrack_2nd.parent_id:
                subtrack_1st = subtrack_2nd
                continue
            
            # Get bounding boxes
            bbox1 = subtrack_1st.bboxes[-1]  # Last bbox of first subtrack
            bbox2 = subtrack_2nd.bboxes[0]   # First bbox of second subtrack
            
            # Calculate centers
            x_1, y_1, w_1, h_1 = bbox1[:4]
            x_2, y_2, w_2, h_2 = bbox2[:4]
            
            cx1, cy1 = x_1 + w_1/2, y_1 + h_1/2
            cx2, cy2 = x_2 + w_2/2, y_2 + h_2/2
            
            # Check distance constraints
            dx = abs(cx1 - cx2)
            dy = abs(cy1 - cy2)
            
            if dx > max_x_range or dy > max_y_range:
                return False
            
            subtrack_1st = subtrack_2nd
        
        return True

    def update_distance_matrix_after_merge(self, dist_matrix: cp.ndarray, merged_idx: int, 
                                         removed_idx: int, tracklets: Dict, 
                                         tracklet_ids: List) -> cp.ndarray:
        """
        Smart distance matrix update - only recompute affected row/column.
        This is a MAJOR optimization over full matrix recomputation.
        """
        n = len(tracklet_ids)
        
        # Remove the merged tracklet's row and column
        mask = cp.ones(n, dtype=cp.bool_) if self.use_gpu else np.ones(n, dtype=bool)
        mask[removed_idx] = False
        
        # Create new smaller matrix
        new_size = n - 1
        if self.use_gpu:
            new_dist_matrix = cp.zeros((new_size, new_size), dtype=cp.float32)
        else:
            new_dist_matrix = np.zeros((new_size, new_size), dtype=np.float32)
        
        # Copy existing distances (excluding removed row/column)
        old_indices = cp.where(mask)[0] if self.use_gpu else np.where(mask)[0]
        for i, old_i in enumerate(old_indices):
            for j, old_j in enumerate(old_indices):
                if old_i != merged_idx and old_j != merged_idx:
                    new_dist_matrix[i, j] = dist_matrix[old_i, old_j]
        
        # Update the merged tracklet's distances (only one row/column)
        merged_tracklet = tracklets[tracklet_ids[merged_idx]]
        
        # Extract features for the merged tracklet
        if merged_tracklet.features:
            if self.use_gpu:
                merged_features = cp.asarray(np.stack(merged_tracklet.features))
            else:
                merged_features = np.stack(merged_tracklet.features)
            
            merged_times = set(merged_tracklet.times)
            
            new_merged_idx = merged_idx if merged_idx < removed_idx else merged_idx - 1
            
            for i, old_idx in enumerate(old_indices):
                if old_idx == merged_idx:
                    continue
                
                other_tracklet = tracklets[tracklet_ids[old_idx]]
                other_times = set(other_tracklet.times)
                
                # Check temporal overlap
                if merged_times & other_times:
                    distance = 1.0
                elif not other_tracklet.features:
                    distance = 1.0
                else:
                    if self.use_gpu:
                        other_features = cp.asarray(np.stack(other_tracklet.features))
                    else:
                        other_features = np.stack(other_tracklet.features)
                    
                    pairwise_distances = self.compute_cosine_distances_batch(
                        merged_features, other_features
                    )
                    distance = float(cp.mean(pairwise_distances))
                
                # Update matrix symmetrically
                new_dist_matrix[new_merged_idx, i] = distance
                new_dist_matrix[i, new_merged_idx] = distance
        
        return new_dist_matrix

    def merge_tracklets_gpu(self, tracklets: Dict, merge_dist_thres: float, 
                           max_x_range: float, max_y_range: float) -> Dict:
        """
        GPU-optimized tracklet merging with smart matrix updates.
        Preserves exact logic from original but with major optimizations.
        """
        if len(tracklets) <= 1:
            return tracklets
        
        log.info(f"ðŸš€ GPU merging {len(tracklets)} tracklets (threshold: {merge_dist_thres})")
        start_time = time.time()
        
        # Make working copy
        working_tracklets = tracklets.copy()
        tracklet_ids = list(working_tracklets.keys())
        
        # Initial distance matrix computation
        dist_matrix = self.get_distance_matrix_gpu(working_tracklets)
        
        merge_count = 0
        max_iterations = len(tracklets) * 2  # Safety limit
        
        for iteration in range(max_iterations):
            # Create mask for non-diagonal elements
            n = dist_matrix.shape[0]
            if n <= 1:
                break
            
            if self.use_gpu:
                mask = ~cp.eye(n, dtype=cp.bool_)
                masked_distances = cp.where(mask, dist_matrix, cp.inf)
            else:
                mask = ~np.eye(n, dtype=bool)
                masked_distances = np.where(mask, dist_matrix, np.inf)
            
            # Find minimum distance
            min_distance = cp.min(masked_distances) if self.use_gpu else np.min(masked_distances)
            
            if float(min_distance) >= merge_dist_thres:
                break  # No more merges possible
            
            # Find indices of minimum distance
            if self.use_gpu:
                min_idx = cp.unravel_index(cp.argmin(masked_distances), masked_distances.shape)
                track1_idx, track2_idx = int(min_idx[0]), int(min_idx[1])
            else:
                min_idx = np.unravel_index(np.argmin(masked_distances), masked_distances.shape)
                track1_idx, track2_idx = min_idx[0], min_idx[1]
            
            # Get tracklets
            tid1, tid2 = tracklet_ids[track1_idx], tracklet_ids[track2_idx]
            track1, track2 = working_tracklets[tid1], working_tracklets[tid2]
            
            # Check temporal overlap
            if set(track1.times) & set(track2.times):
                # Mark as unmergeable and continue
                dist_matrix[track1_idx, track2_idx] = float('inf')
                dist_matrix[track2_idx, track1_idx] = float('inf')
                continue
            
            # Check spatial constraints
            if not self.check_spatial_constraints_vectorized(track1, track2, max_x_range, max_y_range):
                # Mark as unmergeable and continue
                dist_matrix[track1_idx, track2_idx] = float('inf')
                dist_matrix[track2_idx, track1_idx] = float('inf')
                continue
            
            # Perform merge
            log.debug(f"Merging tracklets {tid1} + {tid2} (distance: {min_distance:.4f})")
            
            # Merge track2 into track1
            track1.features.extend(track2.features)
            track1.times.extend(track2.times)
            track1.bboxes.extend(track2.bboxes)
            track1.scores.extend(track2.scores)
            
            # Update working tracklets
            working_tracklets[tid1] = track1
            del working_tracklets[tid2]
            
            # Update tracklet_ids and matrix
            removed_idx = track2_idx
            tracklet_ids.pop(removed_idx)
            
            # Smart matrix update instead of full recomputation
            dist_matrix = self.update_distance_matrix_after_merge(
                dist_matrix, track1_idx, removed_idx, working_tracklets, tracklet_ids
            )
            
            # Update indices after removal
            if track1_idx > removed_idx:
                track1_idx -= 1
            
            merge_count += 1
        
        elapsed = time.time() - start_time
        log.info(f"âœ… GPU merging complete: {len(tracklets)} â†’ {len(working_tracklets)} tracklets "
                f"({merge_count} merges in {elapsed:.2f}s)")
        
        return working_tracklets

    def merge_tracklets_batched_gpu(self, tracklets: Dict, seq2Dist: Dict, batch_size: int = 50,
                                   seq_name: str = None, max_x_range: float = None,
                                   max_y_range: float = None, merge_dist_thres: float = None) -> Dict:
        """
        GPU-optimized batched merging with same logic as original.
        """
        temp_tracklets = {}
        tracklet_items = list(tracklets.items())
        
        log.info(f"ðŸ”¥ GPU batched processing: {len(tracklet_items)} tracklets, batch_size={batch_size}")
        
        # Process batches
        for i in range(0, len(tracklet_items), batch_size):
            batch_tracklets = dict(tracklet_items[i:i+batch_size])
            log.debug(f"Processing batch {i//batch_size + 1}: {len(batch_tracklets)} tracklets")
            
            merged_batch = self.merge_tracklets_gpu(
                batch_tracklets, merge_dist_thres, max_x_range, max_y_range
            )
            
            temp_tracklets.update(merged_batch)
            log.debug(f"Batch result: {len(merged_batch)} tracklets remaining")
        
        # Final cross-batch merge
        log.info(f"ðŸ”— Final cross-batch merging: {len(temp_tracklets)} tracklets")
        final_result = self.merge_tracklets_gpu(
            temp_tracklets, merge_dist_thres, max_x_range, max_y_range
        )
        
        return final_result


# High-level API functions matching original interface
def detect_id_switch(embs, eps=None, min_samples=None, max_clusters=None):
    """GPU-optimized version of detect_id_switch with same interface."""
    refiner = CuPyTrackletRefiner()
    return refiner.detect_id_switch(embs, eps, min_samples, max_clusters)


def split_tracklets(tmp_trklets, eps=None, max_k=None, min_samples=None, len_thres=None):
    """GPU-optimized version of split_tracklets with same interface."""
    refiner = CuPyTrackletRefiner()
    return refiner.split_tracklets(tmp_trklets, eps, max_k, min_samples, len_thres)


def get_spatial_constraints(tid2track, factor):
    """GPU-optimized version of get_spatial_constraints with same interface."""
    refiner = CuPyTrackletRefiner()
    return refiner.get_spatial_constraints(tid2track, factor)


def merge_tracklets(tracklets, merge_dist_thres, max_x_range, max_y_range):
    """GPU-optimized version of merge_tracklets with same interface."""
    refiner = CuPyTrackletRefiner()
    return refiner.merge_tracklets_gpu(tracklets, merge_dist_thres, max_x_range, max_y_range)


def merge_tracklets_batched(tracklets, seq2Dist, batch_size=50, seq_name=None,
                           max_x_range=None, max_y_range=None, merge_dist_thres=None):
    """GPU-optimized version of merge_tracklets_batched with same interface."""
    refiner = CuPyTrackletRefiner()
    return refiner.merge_tracklets_batched_gpu(
        tracklets, seq2Dist, batch_size, seq_name, max_x_range, max_y_range, merge_dist_thres
    )


def check_spatial_constraints(trk_1, trk_2, max_x_range, max_y_range):
    """GPU-optimized version of check_spatial_constraints with same interface."""
    refiner = CuPyTrackletRefiner()
    return refiner.check_spatial_constraints_vectorized(trk_1, trk_2, max_x_range, max_y_range)


# Additional utility functions
def find_consecutive_segments(track_times):
    """Same as original find_consecutive_segments."""
    refiner = CuPyTrackletRefiner()
    return refiner.find_consecutive_segments(track_times)


def query_subtracks(seg1, seg2, track1, track2):
    """Same as original query_subtracks."""
    refiner = CuPyTrackletRefiner()
    return refiner.query_subtracks(seg1, seg2, track1, track2)


def save_results(sct_output_path, tracklets):
    """
    Saves the final tracklet results into a specified path.
    Same as original implementation.
    """
    results = []
    for track_id, track in tracklets.items():
        tid = track.track_id
        for instance_idx, frame_id in enumerate(track.times):
            bbox = track.bboxes[instance_idx]
            results.append([
                frame_id, tid, bbox[0], bbox[1], bbox[2], bbox[3], 1, -1, -1, -1
            ])
    
    results = sorted(results, key=lambda x: x[0])
    txt_results = []
    for line in results:
        txt_results.append(
            f"{line[0]},{line[1]},{line[2]:.2f},{line[3]:.2f},{line[4]:.2f},"
            f"{line[5]:.2f},{line[6]},{line[7]},{line[8]},{line[9]}\n"
        )
    
    with open(sct_output_path, 'w') as f:
        f.writelines(txt_results)
    log.info(f"Saved results to {sct_output_path}")


# Performance benchmarking
def benchmark_gpu_vs_cpu(tracklets: Dict, merge_dist_thres: float, 
                        max_x_range: float, max_y_range: float):
    """
    Benchmark GPU vs CPU performance for tracklet merging.
    """
    print("ðŸ Performance Benchmark: GPU vs CPU")
    print(f"   Tracklets: {len(tracklets)}")
    print(f"   Threshold: {merge_dist_thres}")
    
    # Import original CPU version for comparison
    try:
        from .refine_tracklets_batched import merge_tracklets as cpu_merge_tracklets
    except ImportError:
        print("âŒ Could not import CPU version for comparison")
        return None
    
    # CPU benchmark
    print("\nâ±ï¸  CPU Implementation...")
    start_time = time.time()
    cpu_result = cpu_merge_tracklets(tracklets.copy(), merge_dist_thres, max_x_range, max_y_range)
    cpu_time = time.time() - start_time
    
    # GPU benchmark
    print("\nðŸš€ GPU Implementation...")
    start_time = time.time()
    gpu_result = merge_tracklets(tracklets.copy(), merge_dist_thres, max_x_range, max_y_range)
    gpu_time = time.time() - start_time
    
    # Results
    speedup = cpu_time / gpu_time if gpu_time > 0 else float('inf')
    print(f"\nðŸ“Š Results:")
    print(f"   CPU Time: {cpu_time:.2f}s â†’ {len(cpu_result)} tracklets")
    print(f"   GPU Time: {gpu_time:.2f}s â†’ {len(gpu_result)} tracklets")
    print(f"   Speedup: {speedup:.1f}x")
    
    return {
        'cpu_time': cpu_time, 
        'gpu_time': gpu_time, 
        'speedup': speedup,
        'cpu_tracklets': len(cpu_result),
        'gpu_tracklets': len(gpu_result)
    }
